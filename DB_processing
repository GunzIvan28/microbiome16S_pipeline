User manual DB processing :



Snakemake is a workflow management system. We use it to create data analysis pipelines, so such as the implementation of the database.


For that, 5 files are created (the rules with EzBioCloud.rules; for the script R the file DB_EzBioCloud_processing.R; the parameters of configuration with config_DB.yaml; the file containing the addition of the various rules Snakefile_DB and the environment necessary for the execution of the R script thanks to the R_DB_processing.yml file).

The file "EzBioCloud.rules" will allow to execute the command lines and scripts of the download of the database to the recovery of the processed database. This pipeline will generate some log and output files which are mostly future input files for the next step. The last files obtained are the results of the extraction of the V3 - V4 regions and of the dereplication and the taxonomic assembly according to the sequence numbers.

A file "config_DB.yaml" allowing to have the parameters of some data and the localization, path of the basic files (download of the database EzBioCloud). This file must be in the directory where the snakemake command is run in the "microbiome16S_pipeline" directory.


When a database update is done :
- You only have to change the two basic files who is in microbiome16S_pipeline/data/ezbiocloud.  
- Leave the following code separately if the names of these files are different from the previous ones you have to change them so that it matches to the system can easily find them in the rules file "EzBioCloud.rules" and config_DB.yaml.



The DB_processing command isÂ :
snakemake --snakefile $pipeline_folder/Snakefile_DB --use-conda --conda-prefix $pipeline_folder/miniconda3/  --cores 1  --configfile config_DB.yaml     
