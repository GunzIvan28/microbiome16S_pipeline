
rule Import_DB :
    conda:
        "../../envs/QIIME2-2020.02.yml"
    singularity:
        "docker://qiime2/core:2020.2" 
    input :
        config["DBpath_seq"]
    output :
        temp(workflow.basedir + "/data/" + config["output_dir"] + "/DB_seq.qza")
    threads :
        1
    shell :
         '''
        qiime tools import \
        --type 'FeatureData[Sequence]' \
        --input-path {input} \
        --output-path {output} 
        '''


rule Extract_amp :
    conda:
        "../../envs/QIIME2-2020.02.yml"
    singularity:
        "docker://qiime2/core:2020.2" 
    input :
        workflow.basedir + "/data/" + config["output_dir"] + "/DB_seq.qza"
    output :
        temp(workflow.basedir + "/data/" + config["output_dir"] + "/DB_amp_seq.qza")
    params :
        primer_forward = config["forward_primer"],
        primer_reverse = config["reverse_primer"],
        length = config["length_max"]
    threads :
        1
    shell :
         '''
        qiime feature-classifier extract-reads \
        --i-sequences {input} \
        --p-f-primer {params[primer_forward]} \
        --p-r-primer {params[primer_reverse]} \
        --p-trunc-len {params[length]} \
        --o-reads {output} 
        '''



rule Export :
    conda:
        "../../envs/QIIME2-2020.02.yml"
    singularity:
        "docker://qiime2/core:2020.2" 
   input :
        workflow.basedir + "/data/" + config["output_dir"] + "/DB_amp_seq.qza"
   output :
        temp(workflow.basedir + "/data/" + config["output_dir"] + "/dna-sequences.fasta")
   threads :
        1
   shell :
         '''
        qiime tools export \
        --input-path {input} \
        --output-path $(dirname {output}) 
        '''



rule Vsearch :
    conda:
        "../../envs/QIIME2-2020.02.yml"
    singularity:
        "docker://qiime2/core:2020.2" 
    input :
        workflow.basedir + "/data/" + config["output_dir"] + "/dna-sequences.fasta"
    output :
        fasta = workflow.basedir + "/data/" + config["output_dir"] + "/DB_amp.fasta",
        uc = workflow.basedir + "/data/" + config["output_dir"] + "/log/DB_amp.uc"
    log :
        workflow.basedir + "/data/" + config["output_dir"] + "/log/DB_amp.log"
    threads :
        1
    shell :
         '''
        vsearch \
        --derep_fulllength {input} \
        --output {output[fasta]} \
        --uc {output[uc]} \
        2> {log}
        '''



rule Taxonomy :
    conda:
        "../../envs/amplicons_r_utils.yml"
    singularity:
        "docker://metagenlab/amplicons_r_utils:v.1.0"  
    input :
        tax = config["DBpath_tax"],
        uc = workflow.basedir + "/data/" + config["output_dir"] + "/log/DB_amp.uc"
    output :
        formatted_tax = workflow.basedir + "/data/" + config["output_dir"] + "/DB_amp_taxonomy.txt",
        all = workflow.basedir + "/data/" + config["output_dir"] + "/DB_amp_all_taxonomy.txt",
        problematic = workflow.basedir + "/data/" + config["output_dir"] + "/log/probematic_taxa.txt"
    log :
       workflow.basedir + "/data/" + config["output_dir"] + "/log/DB_amp_taxonomy.log"
    params:
        numbers_species = config["numbers_species"],
        numbers_genus = config["numbers_genus"]
    threads :
        1
    script :
        "scripts/DB_tax_formatting.R"


rule dada2_prep_tax_db:
    conda:
        "../../envs/DADA2_in_R.yml"
    singularity:
        "docker://quay.io/biocontainers/bioconductor-dada2:1.12.1--r36he1b5a44_0"
    input:
        ref_seqs = "{prefix}/{tax_DB}/DB_amp.fasta",
        ref_tax = "{prefix}/{tax_DB}/DB_amp_taxonomy.txt"
    output:
        King_to_Species ="{prefix}/{tax_DB}/DADA2_DB_amp_taxonomy_King_to_Species.txt",
        King_to_Genus = "{prefix}/{tax_DB}/DADA2_DB_amp_taxonomy_King_to_Genus.txt",
        Genus_species =  "{prefix}/{tax_DB}/DADA2_DB_amp_taxonomy_Genus_species.txt"
    log:
        workflow.basedir + "{prefix}/{tax_DB}/DB_amp_taxonomy_dada2_prep.log"
    threads:
        1
    script:
        "scripts/dada2_prep_tax.R"



rule decipher_prep_fasta:
    conda:
        "../../envs/amplicons_r_utils.yml"
    singularity:
        "docker://metagenlab/amplicons_r_utils:v.1.0"  
    input:
        ref_tax = "{prefix}/{tax_DB}/DB_amp_taxonomy.txt",
        ref_seqs = "{prefix}/{tax_DB}/DB_amp.fasta",
    output:
        "{prefix}/{tax_DB}/{tax_DB}/Decipher_DB_amp_taxonomy_decipher.fasta",
    log:
        "{prefix}/{tax_DB}/DB_amp_taxonomy_decipher_fasta.log"
    threads:
        1
    script:
        "scripts/decipher_prep_tax.R"


rule decipher_train_tax:
    conda:
        "../../envs/decipher.yml"
    singularity:
        "docker://metagenlab/amplicons_decipher:v.1.0"
    input:
        decipher_seqs = "{prefix}/{tax_DB}/Decipher_DB_amp_taxonomy_decipher.fasta"
    output:
        trained_tax = "{prefix}/{tax_DB}/Decipher_DB_amp_taxonomy_decipher_trained_tax.rds",
        training_plot = "{prefix}/{tax_DB}/Decipher_DB_amp_taxonomy_decipher_trained_plot.pdf",
    log:
        "{prefix}/{tax_DB}/DB_amp_taxonomy_decipher_tax_tree.log",
    threads:
        1
    script:
        "scripts/decipher_train_tax.R"


# Original RDP implementation, based on https://john-quensen.com/tutorials/training-the-rdp-classifier/

rule preformat_for_cannonical_rdp:
    conda:
        "../../envs/amplicons_r_utils.yml"
    singularity:
        "docker://metagenlab/amplicons_r_utils:v.1.0"  
    input:
        ref_tax = "{prefix}/{tax_DB}/DB_amp_taxonomy.txt",
        ref_seqs = "{prefix}/{tax_DB}/DB_amp.fasta",
    output:
        formatted_table = "{prefix}/{tax_DB}/RDP_formatted_tax_table.tsv",
    log:
      workflow.basedir + "{prefix}/{tax_DB}/RDP_formatted_tax_table.log",
    threads:
        1
    script:
        "scripts/rdp_prep_tax.R"


rule format_rdp_lineages:
    conda:
        "../../envs/Python2.yml"
    singularity:
        "docker://python:2.7"  
    input:
        formatted_table = "{prefix}/{tax_DB}/RDP_formatted_tax_table.tsv",
    output:
        read4train_tax = "{prefix}/{tax_DB}/RDP_ready4train_lineages.txt",
    params:
        script =  workflow.basedir + "/rules/3_tax_assignment/scripts/lineage2taxTrain.py"
    threads:
        1
    shell:
        '''
        python {params[0]} {input[0]} > {output[0]}
        '''

 
rule format_rdp_add_lineages:
    conda:
        "../../envs/Python2.yml"
    singularity:
        "docker://python:2.7"  
    input:
        taxonomyFile = "{prefix}/{tax_DB}/RDP_formatted_tax_table.tsv",
        fastaFile = "{prefix}/{tax_DB}/DB_amp.fasta",
    output:
        read4train_fasta = "{prefix}/{tax_DB}/RDP_ready4train_seqs.fasta",
    params:
        script =  workflow.basedir + "/rules/3_tax_assignment/scripts/addFullLineage.py"
    threads:
        1
    shell:
        '''
        python {params[0]} {input[0]} {input[1]} > {output[0]}       
        '''


rule train_rdp_classifier:
    conda:
        "../../envs/rdp_tools.yml"
    singularity:
        "docker://quay.io/biocontainers/rdptools:2.0.3--0"
    input:
       read4train_fasta = "{prefix}/{tax_DB}/RDP_ready4train_seqs.fasta",
       read4train_tax = "{prefix}/{tax_DB}/RDP_ready4train_lineages.txt",
    output:
        formatted_table = "{prefix}/{tax_DB}/RDP_train_file/bergeyTrainingTree.xml",
        properties = "{prefix}/{tax_DB}/RDP_train_file/rRNAClassifier.properties"
    log:
      "{prefix}/{tax_DB}/RDP_train_file.log",
    threads:
        1
    resources:
        mem_mb=30000
    shell:
        '''
        classifier -Xmx30g train \
        -o $(dirname {output[0]}) \
        -s {input[0]} \
        -t {input[1]} && \
        echo "bergeyTree=bergeyTrainingTree.xml
        probabilityList=genus_wordConditionalProbList.txt
        probabilityIndex=wordConditionalProbIndexArr.txt
        wordPrior=logWordPrior.txt
        classifierVersion=RDP Naive Bayesian rRNA Classifier Version 2.5, May 2012" > {output[1]}
	    '''