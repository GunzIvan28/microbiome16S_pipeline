

import pandas as pd
import re


rule decompress_assemblies:
    input:
        'assembly_gz/{sample}.fna.gz'
    output:
        'assembly_gz/{sample}.fna'
    shell:
        "zcat {input[0]} > {output[0]}"


rule print_primers_to_files :
    output:
        "InSilico/assembly_fna/Primers.fasta"
    params:
        forward = config["forward_primer"],
        reverse = config["reverse_primer"]
    shell:
        '''
        printf \
        ">Forward|F 
        {params[0]}
        >Right|R
        {params[1]}" >> {output}
        '''


def list_samples(wildcards):
    checkpoint_output = checkpoints.combine_assembly_tables.get(**wildcards).output[0]
    table=pd.read_csv(checkpoint_output,delimiter='\t')
    acc=list(table['AssemblyNames'])
    expd=expand('assembly_gz/{sample}.fna',sample=acc)
    return expd


rule Extract_V3V4 :
    singularity :
        "docker://metagenlab/amplicon_pipeline:v.0.9.7-beta"
    input :
        list_samples,
        "InSilico/assembly_fna/{sample}.fna"
    output :
        "InSilico/PCR/{sample}.fna"
    params:
        min_length = config["merged_min_length"],
        max_length = config["merged_max_length"],
    threads :
        1
    shell :
        '''
        simulate_PCR \
            -primers {input[0]} \
            -db {input[1]} \
            -minlen {params[0]} \
            -maxlen {params[1]} \
            -mm 3 \
            -mux 0 \
            -num_threads 4 \
            -max_target_seqs 1000000000 \
            -word_size 4 \
            -evalue 100000000 \
            -genes 1 \
            -extract_amp 1 \
            -3prime 2 && mv {input[0]}.{input[1]}.amplicons.fasta {output}
         '''




### Combine all extracted sequences in one big fasta
rule merge_all_in_one_fasta:
    input:
        list_samples
    output:
        temp("InSilico/1c_derep/merged_all.fasta")
    shell:
        '''
        cat {input} >> {output}
        '''


### Again, dereplicate all identical sequences after merging. Sequences must at least be twice in dataset to be kept.
rule InSilico_derepicate_all:
    conda:
        "../../envs/QIIME1.yml"
    input:
        "InSilico/1c_derep/merged_all.fasta"
    output:
        "InSilico/2_denoised/dna-sequences.fasta"
    log:
         logging_folder + "InSilico/1c_all_merged_sequences/dereplicate_all.txt"
    shell:
        '''
        vsearch --derep_fulllength {input} \
                --sizeout \
                --minuniquesize 2 \
                --output {output} \
                2> {log}
        '''


### Count the number of occurences of the representative sequences in the samples.
rule InSilico_count_occurences :
    conda:
        "../../envs/QIIME1.yml"
    input:
        samples = list_samples,
        rep_seq = "InSilico/2_denoised/dna-sequences.fasta"
    output:
        "InSilico/2_denoised/countOTUs/{sample}_count_table.txt",
    log:
         logging_folder + "InSilico/2_denoised/countOTUs/{sample}_count_table.txt"
    shell:
        '''
        vsearch --usearch_global {input[samples]} \
        -otutabout {output} \
        -id 1 \
        -strand plus \
        --db {input[rep_seq]} \
        2> {log}
        '''


def list_samples_counts(wildcards):
    checkpoint_output = checkpoints.combine_assembly_tables.get(**wildcards).output[0]
    table=pd.read_csv(checkpoint_output,delimiter='\t')
    acc=list(table['AssemblyNames'])
    expd=expand('InSilico/PCR/{sample}_count_table.txt',sample=acc)
    return expd


### Format count table from InSilico
rule create_InSilico_count_table :
    conda:
        "../../envs/r_visualization.yml"
    input:
        list_samples_counts
    output:
        count_table = "InSilico/2_denoised/count_table.txt"
    log:
        logging_folder +  "InSilico/2_denoised/count_table.txt"
    script:
        "scripts/create_count_table_from_insilico.R"












