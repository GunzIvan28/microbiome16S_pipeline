### Match reads with sample list. By default will take the first column as Sample ID. If OldSampleName present, this column will be used instead to match the rows with the reads. They will be then renamed by the content of the first column.

import pandas
import re



def get_read_naming_patterns(directory):
    result = []
    extension= {}
    for fname in sorted(os.listdir(directory)):
        if fname.endswith("fastq.gz") or fname.endswith("fq.gz") or fname.endswith("fastq") or fname.endswith("fq"):
            regex_str = '(_L0+[1-9]+)?_(R)?(1|2)(\.|_)' #regex for finding R1 and R2, if L001 is present before, it is also included
            regex = re.compile(regex_str)
            ext = re.search(regex, fname)
            if ext is None:
                ext = re.search(r'f(?:ast)?q(?:\.gz)?', fname)
                samp = re.sub("\.$", "", re.search(r'^([^\.]*)\.*', fname).group(0))
                if samp in extension.keys():
                    if ext.group(0).endswith(".gz"):
                        extension[samp] = [ext.group(0)]
                else:
                    extension[samp] = [ext.group(0)]
            else:
                regex_after = re.compile(regex_str+".*")
                regex_before = re.compile(".*"+regex_str)
                read = re.compile(re.search(regex_after, fname).group(0))
                samp = re.sub(regex, '', re.search(regex_before, fname).group(0))
                extension.setdefault(samp, [])
                extension[samp].append(re.sub("^_", "", read.pattern))
    return(extension)

all_samples=pandas.DataFrame()



if "link_directory" in config.keys():
    link_directory = config["link_directory"]
    if not link_directory.endswith("/"):
        link_directory = link_directory + "/"
else:
    link_directory = "links/"

sras_ext = {}
reads_sra = {}

reads_local = {}
original_names = {}
reads_ext = {}
paths  = {}
layout = {}


if "local_samples" not in config.keys() and "sra_samples" not in config.keys():
    raise ValueError("No samples defined in the config file")

if "local_samples" in config.keys():
    local_data = pandas.read_csv(config["local_samples"], sep="\t", index_col=0)
    local_data.index = [str(x) for x in local_data.index]
    all_local_sample_names =  "".join(list(local_data.index))
    if "(" in all_local_sample_names or ")" in all_local_sample_names or "_-_" in all_local_sample_names:
        raise ValueError("Forbidden character in sample name in sample name file")
    if "R1" in list(local_data):
        for sample_name, sample_data in local_data.iterrows():
            if sample_name in paths:
                raise IOError("Identical sample name used multiple times: %s" % sample_name)
            paths[sample_name] =[sample_data.loc["R1"]] 
            reads_ext[sample_name] = "single"
            layout[sample_name] = "single"
            if 'R2' in local_data.columns.values:
                if "R1" in sample_data.loc["R2"]:
                    raise IOError("ATTENTION! R1 flag within R2 filename: %s", sample_data.loc["R2"])
                if sample_data.loc["R2"].strip() != '':
                    paths[sample_name].append(sample_data.loc["R2"])
                    reads_ext[sample_name] = ["R1", "R2"]
                    layout[sample_name] = "paired"
        all_samples = local_data   

        paths = {**paths}             

    else:
        
        reads_local = get_read_naming_patterns(link_directory)            
        original_names = { x : x for x in reads_local.keys() }
        read_correct = {}
        original_correct = {}

        if "OldSampleName" not in list(local_data):

            ## i vs sample et correct vs original Ã  checker!!!!
            for i in list(local_data.index):
                regex = re.compile(r'%s([^a-zA-Z0-9]|$)' % i) # this regex ensures that the matching of the sample names end at the end of the str, to prevent S1 matching S10 for instance
                match = [bool(re.match(regex, x)) for x in sorted(list(original_names.keys()))]
                if sum(match) != 1: #there must be one and only one entry matching one sample name
                    raise ValueError("Problem matching SampleName to read file names")
                sample = str(sorted(list(original_names.keys()))[match.index(True)])
                original_correct[i] = original_names[sample]
                read_correct[i] = reads_local[sample]
                paths[i] = expand(link_directory + sample + "_{reads}" ,  reads = read_correct[i]) 
                print(paths[i])

                if "LibraryLayout" in list(local_data):
                    if local_data.loc[i, "LibraryLayout"].lower()=="paired":
                        reads_ext[i]=["R1", "R2"]
                        layout[i] = "paired"
                    elif local_data.loc[i, "LibraryLayout"].lower()=="single":
                        reads_ext[i]=["single"]
                        layout[i] = "single"
                    else:
                        raise ValueError("Problem in the sra file, LibraryLayout badly defined")
                else:
                    reads_ext[i]=["R1", "R2"]
                    layout[i] = "paired"

                
        else:
            for i in list(local_data["OldSampleName"]):
                regex = re.compile(r'%s([^a-zA-Z0-9]|$)' % i)
                match = [bool(re.match(regex, x)) for x in sorted(list(original_names.keys()))]
                if sum(match) != 1:
                    raise ValueError("Problem matching OldSampleName to read file names")
                old_sample_name=str(sorted(list(original_names.keys()))[match.index(True)])
                sample=str(local_data.index[local_data['OldSampleName'] == i][0])
                original_correct[sample] = original_names[old_sample_name]
                read_correct[i] = reads_local[old_sample_name]
                paths[i] = link_directory + read_correct[i] 
                print(path[i])

                if "LibraryLayout" in list(local_data):
                    if local_data.loc[sample, "LibraryLayout"].lower()=="paired":
                        reads_ext[sample]=["R1", "R2"]
                    elif local_data.loc[i, "LibraryLayout"].lower()=="single":
                        reads_ext[sample]=["single"]
                    else:
                        raise ValueError("Problem in the sra file, LibraryLayout badly defined")
                else:
                    reads_ext[sample]=["R1", "R2"]

        original_names = original_correct
        reads_local = read_correct
        reads_ext = reads_ext


        #print(original_names)
        print(read_correct)

        all_samples=local_data




if "sra_samples" in config.keys():
    sra_data = pandas.read_csv(config["sra_samples"], sep="\t", index_col=0).drop_duplicates()
    all_sra_sample_names = "".join(list(sra_data.index))
    if "(" in all_sra_sample_names or ")" in all_sra_sample_names or "_-_" in all_sra_sample_names:
        raise ValueError("Forbidden character in sample name in sra file")
    for i in list(sra_data.index):
        sample_name = str(i).replace(" ", "_").replace("&", "and").replace(":", "-")
        if sample_name in reads_sra.keys(): # if the sample name is already used, add _(n+1) at the end
            sample_name = sample_name+"_"+str(list(reads_sra.keys()).count(sample_name))
        reads_sra[sample_name]=str(i)
        if sra_data.loc[i, "LibraryLayout"].lower()=="paired":
            sras_ext[sample_name]=["1.fastq.gz", "2.fastq.gz"]
            reads_ext[sample_name]=["R1", "R2"]
        elif sra_data.loc[i, "LibraryLayout"].lower()=="single":
            sras_ext[sample_name] = ["fastq.gz"]
            reads_ext[sample_name]=["single"]
        else:
            raise ValueError("Problem in the sra file, LibraryLayout badly defined")
    all_samples=sra_data
    config["local_samples"] =  config["sra_samples"]

        # all_samples.loc[sample_name, "Replicate"]=sra_data.loc[i, "Replicate"]
read_naming = {**reads_local, **sras_ext}
original_names = {**original_names, **reads_sra}





### Define values of grouping keys
def get_grouping_key(column_of_interest):

    file_list = []

    for i in set(column_of_interest):
        combined_values = expand("{column_of_interest}/{column_values}", column_of_interest = i, column_values = list(set(all_samples[i])))
        file_list = file_list + combined_values
    return(file_list)

### Define rarefaction levels (values in config + no rarefaction)
def get_rarefaction_key(rarefaction_values):
    file_list = []
    for i in set(rarefaction_values):
        combined_values = expand("rarefaction_{rarefaction_values}", rarefaction_values = i)
        file_list = file_list + combined_values
    file_list = file_list + ["norarefaction"]

    return(file_list)


# Transform the collapse levels from the plotting taxonomic rank
def get_taxa_collapse_level_key(collapse_level):

    file_list = []
    for i in set(collapse_level):
        if i == "OTU":
            value = 'no_collapse'
        elif i == "Species" :
            value = 'collap_7'
        elif i == "Genus" :
            value = 'collap_6'
        elif i == "Family" :
            value = 'collap_5'
        elif i == "Order" :
            value = 'collap_4'
        elif i == "Class" :
            value = 'collap_3'
        elif i == "Phylum" :
            value = 'collap_2'
        elif i == "Kingdom" :
            value = 'collap_1'
        else :
            raise ValueError("Forbidden value in taxa level for barplots")
        file_list.append(value)
    file_list = file_list + ["no_collapse"]
    return(file_list)



## Set of function to generate list of output from config ##############################################################

### Light output, including QC, count table, consensus sequences and taxonomic assignement
def light_output_list():
    output = []
    output = MultiQC
    output.append(light_output)
    if "DADA2" in config["denoiser"]:
        output.append("DADA2/2_denoised/DADA2_denoising_stats.tsv")
    return(output)

### Basic output, diagnostic plots, KRONA plots and rarefaction curves
def basic_plots_list():
    output = []
    output = light_output_list()
    output.append(basic_plots)
    return(output)

### Complete set of phyloseq, in option including transposed count table and metadata (wide to long)
def phyloseq_output_list():
    output = []
    output = basic_plots_list()
    output.append(phyloseq)
    if config["melted_phyloseq"] == True:
        output.append(phyloseq_melted)
    if config["transposed_tables"] == True:
        output.append(transposed_output)
    return(output)


### Qiime2 outputs, offering interactive visualization of the data
def Qiime2_output_list():
    output = []
    output = basic_plots_list()
    if config["Qiime2_basic_output_visualization"] == True:
        output.append(Qiime2_vis_qzv)
    return(output)

### PICRUSt2 outputs, to predict genomic content based on taxonomic profiles
def PICRUSt2_list():
    output = []
    output = basic_plots_list()
    output.append(picrust2)
    return(output)

### Rule all, the default rule including all default output (not PICRUSt2, since long to compute)
def rule_all_list():
    output = []
    output.append(basic_plots_list())
    output.append(Qiime2_vis_qzv)
    output.append(phyloseq_output_list())
    return(output)
