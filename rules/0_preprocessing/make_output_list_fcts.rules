## Set of functions manipulating the sample list and the config file to generate the desired output ####################

### Match reads with sample list. By default will take the first column as Sample ID. If OldSampleName present, this column will be used instead to match the rows with the reads. They will be then renamed by the content of the first column.

import pandas
import re

def get_read_naming_patterns(directory):
    result = []
    extension= {}
    for fname in sorted(os.listdir(directory)):
        if fname.endswith("fastq.gz") or fname.endswith("fq.gz") or fname.endswith("fastq") or fname.endswith("fq"):
            regex_str = '(_L0+[1-9]+)?_(R)?(1|2)(\.|_)' #regex for finding R1 and R2, if L001 is present before, it is also included
            regex = re.compile(regex_str)
            ext = re.search(regex, fname)
            if ext is None:
                ext = re.search(r'f(?:ast)?q(?:\.gz)?', fname)
                samp = re.sub("\.$", "", re.search(r'^([^\.]*)\.*', fname).group(0))
                if samp in extension.keys():
                    if ext.group(0).endswith(".gz"):
                        extension[samp] = [ext.group(0)]
                else:
                    extension[samp] = [ext.group(0)]
            else:
                regex_after = re.compile(regex_str+".*")
                regex_before = re.compile(".*"+regex_str)
                read = re.compile(re.search(regex_after, fname).group(0))
                samp = re.sub(regex, '', re.search(regex_before, fname).group(0))
                extension.setdefault(samp, [])
                # print(extension)
                extension[samp].append(re.sub("^_", "", read.pattern))
    return(extension)

all_samples=pandas.DataFrame()

if "link_directory" in config.keys():
    link_directory = config["link_directory"]
    if not link_directory.endswith("/"):
        link_directory = link_directory + "/"
else:
    link_directory = "links/"

sras_ext = {}
reads_sra = {}

reads_local = {}
original_names = {}

if "local_samples" not in config.keys() and "sra_samples" not in config.keys():
    raise ValueError("No samples defined in the config file")

if "local_samples" in config.keys():
    local_data = pandas.read_csv(config["local_samples"], sep="\t", index_col=0)
    local_data.index = [str(x) for x in local_data.index]
    all_local_sample_names =  "".join(list(local_data.index))
    if "(" in all_local_sample_names or ")" in all_local_sample_names or "_-_" in all_local_sample_names:
        raise ValueError("Forbidden character in sample name in sample name file")
    reads_local = get_read_naming_patterns(link_directory)
    original_names = { x : x for x in reads_local.keys() }
    read_correct = {}
    original_correct = {}
    if "OldSampleName" not in list(local_data):
        for i in list(local_data.index):
            regex = re.compile(r'%s([^a-zA-Z0-9]|$)' % i) # this regex ensures that the matching of the sample names end at the end of the str, to prevent S1 matching S10 for instance
            match = [bool(re.match(regex, x)) for x in sorted(list(original_names.keys()))]
            if sum(match) != 1: #there must be one and only one entry matching one sample name
                raise ValueError("Problem matching SampleName to read file names")
            sample = str(sorted(list(original_names.keys()))[match.index(True)])
            original_correct[i] = original_names[sample]
            read_correct[i] = reads_local[sample]
    else:
        for i in list(local_data["OldSampleName"]):
            regex = re.compile(r'%s([^a-zA-Z0-9]|$)' % i)
            match = [bool(re.match(regex, x)) for x in sorted(list(original_names.keys()))]
            if sum(match) != 1:
                raise ValueError("Problem matching OldSampleName to read file names")
            old_sample_name=str(sorted(list(original_names.keys()))[match.index(True)])
            sample=str(local_data.index[local_data['OldSampleName'] == i][0])
            original_correct[sample] = original_names[old_sample_name]
            read_correct[sample] = reads_local[old_sample_name]
    original_names = original_correct
    reads_local = read_correct
    all_samples=local_data

if "sra_samples" in config.keys():
    sra_data = pandas.read_csv(config["sra_samples"], sep="\t", index_col=0).drop_duplicates()
    all_sra_sample_names = "".join([str(i) for i in list(sra_data["SampleName"])])
    if "(" in all_sra_sample_names or ")" in all_sra_sample_names or "_-_" in all_sra_sample_names:
        raise ValueError("Forbidden character in sample name in sra file")
    for i in sra_data.index:
        sample_name = str(sra_data.loc[i, "SampleName"]).replace(" ", "_").replace("&", "and").replace(":", "-")
        if sample_name in reads_sra.keys(): # if the sample name is already used, add _(n+1) at the end
            sample_name = sample_name+"_"+str(list(reads_sra.keys()).count(sample_name))
        reads_sra[sample_name]=str(i)
        if sra_data.loc[i, "LibraryLayout"].lower()=="paired":
            sras_ext[sample_name]=["1.fastq.gz", "2.fastq.gz"]
        elif sra_data.loc[i, "LibraryLayout"].lower()=="single":
            sras_ext[sample_name] = ["fastq.gz"]
        else:
            raise ValueError("Problem in the sra file, LibraryLayout badly defined")
        # all_samples.loc[sample_name, "Replicate"]=sra_data.loc[i, "Replicate"]



read_naming = {**reads_local, **sras_ext}
original_names = {**original_names, **reads_sra}

### Define samples to keep
def get_grouping_key(column_of_interest):

    filtered_all_samples = all_samples.loc[all_samples[config['filter_meta_column']]  == config['filter_column_value']]

    file_list = []

    for i in set(column_of_interest):
        combined_values = expand("{column_of_interest}/{column_values}", column_of_interest = i, column_values = list(set(filtered_all_samples[i])))
        file_list = file_list + combined_values
    return(file_list)

### Define rarefaction levels (values in config + no rarefaction)
def get_rarefaction_key(rarefaction_values):
    file_list = []
    for i in set(rarefaction_values):
        combined_values = expand("rarefaction_{rarefaction_values}", rarefaction_values = i)
        file_list = file_list + combined_values
    file_list = file_list + ["norarefaction"]

    return(file_list)


# Transform the collapse levels from the plotting taxonomic rank
def get_taxa_collapse_level_key(collapse_level):

    file_list = []
    for i in set(collapse_level):
        if i == "OTU":
            value = 'no_collapse'
        elif i == "Species" :
            value = 'collap_7'
        elif i == "Genus" :
            value = 'collap_6'
        elif i == "Family" :
            value = 'collap_5'
        elif i == "Order" :
            value = 'collap_4'
        elif i == "Class" :
            value = 'collap_3'
        elif i == "Phylum" :
            value = 'collap_2'
        elif i == "Kingdom" :
            value = 'collap_1'
        else :
            raise ValueError("Forbidden value in taxa level for barplots")
        file_list.append(value)
    file_list = file_list + ["no_collapse"]
    return(file_list)


### Define level of grouping of reads for plotting from config file
def get_filtering_key(filtering):

    file_list = []

    for i in set(filtering):
        if i == "nofiltering" :
            filt = ["nofiltering_0"]
        elif i == "absolute" :
            filt =  expand("{filter}_{filtering_value}" , filter = i, filtering_value = config["absolute_filtering_value"])
        elif i == "relative" :
            filt =  expand("{filter}_{filtering_value}" , filter = i, filtering_value = config["relative_filtering_value"])
        else :
            raise ValueError("Forbidden value for filtering type")

        file_list = file_list + filt

    return(file_list)


## Set of function to generate list of output from config ##############################################################

### Light output, including QC, count table, consensus sequences and taxonomic assignement
def light_output_list():
    output = []
    output = MultiQC
    output.append(light_output)
    if "DADA2" in config["denoiser"]:
        output.append("DADA2/2_denoised/DADA2_denoising_stats.tsv")
    return(output)

### Basic output, diagnostic plots, KRONA plots and rarefaction curves
def basic_plots_list():
    output = []
    output = light_output_list()
    output.append(basic_plots)
    return(output)

### Complete set of phyloseq, in option including transposed count table and metadata (wide to long)
def phyloseq_output_list():
    output = []
    output = basic_plots_list()
    output.append(phyloseq)
    if config["transposed_tables"] == True:
        output.append(transposed_output)
    return(output)

### Complete set of home-made plots, as defined in config file
def plots_output_list():
    output = []
    output = basic_plots_list()
    if config["Barplots"] == True:
        output.append(barplots)
    if config["Heatmaps"] == True:
        output.append(heatmaps)
    if config["Alpha_divs"] == True:
        output.append(alpha_diversities)
    if config["Distance_ordinations"] == True:
        output.append(distance_ordinations)
    if config["Constrained_ordinations"] == True:
        output.append(constrained_ordinations)
    if config["Unconstrained_ordinations"] == True:
        output.append(unconstrained_ordinations)
    return(output)

### Qiime2 outputs, offering interactive visualization of the data
def Qiime2_output_list():
    output = []
    output = basic_plots_list()
    if config["Qiime2_basic_output_visualization"] == True:
        output.append(Qiime2_vis_qzv)
    return(output)

### PICRUSt2 outputs, to predict genomic content based on taxonomic profiles
def PICRUSt2_list():
    output = []
    output = basic_plots_list()
    output.append(picrust2)
    return(output)

### Rule all, the default rule including all default output (not PICRUSt2, since long to compute)
def rule_all_list():
    output = []
    output.append(phyloseq_output_list())
    output.append(plots_output_list())
    output.append(Qiime2_vis_qzv)
    return(output)
